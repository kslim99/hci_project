In the last three years, our object classification and detection capabilities 
have dramatically improved due to advances in deep learning and convolutional networks [10].
One encouraging news is that most of this progress is not
just the result of more powerful hardware, larger datasets
and bigger models, but mainly a consequence of new ideas,
algorithms and improved network architectures. No new
data sources were used, for example, by the top entries
in the ILSVRC 2014 competition besides the classification
dataset of the same competition for detection purposes. Our
GoogLeNet submission to ILSVRC 2014 actually uses 12
times fewer parameters than the winning architecture of
Krizhevsky et al [9] from two years ago, while being significantly more accurate. 
On the object detection front, the
biggest gains have not come from naive application of bigger and bigger deep networks, 
but from the synergy of deep
architectures and classical computer vision, like the R-CNN
algorithm by Girshick et al [6].
Another notable factor is that with the ongoing traction
of mobile and embedded computing, the efficiency of our
algorithms – especially their power and memory use – gains
importance. It is noteworthy that the considerations leading
to the design of the deep architecture presented in this paper
included this factor rather than having a sheer fixation on
accuracy numbers. For most of the experiments, the models
were designed to keep a computational budget of 1.5 billion
multiply-adds at inference time, so that the they do not end
up to be a purely academic curiosity, but could be put to real
world use, even on large datasets, at a reasonable cost.
In this paper, we will focus on an efficient deep neural
network architecture for computer vision, codenamed Inception, 
which derives its name from the Network in network paper by 
Lin et al [12] in conjunction with the famous
“we need to go deeper” internet meme [1]. In our case, the
word “deep” is used in two different meanings: first of all,
in the sense that we introduce a new level of organization
in the form of the “Inception module” and also in the more
direct sense of increased network depth. In general, one can
view the Inception model as a logical culmination of [12]
while taking inspiration and guidance from the theoretical
work by Arora et al [2]. The benefits of the architecture are
experimentally verified on the ILSVRC 2014 classification
and detection challenges, where it significantly outperforms
the current state of the art.
